{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24a35b1c",
   "metadata": {},
   "source": [
    "# DCC-analyse med EGARCH-modell\n",
    "\n",
    "Denne anaylsen undersøker den dynamiske samvariasjonen mellom to finansielle tidsserier ved bruk av EGARCH og DCC. Modellene estimeres basert på daglige strømpriser fra Norge og Tyskland i peiroden 2019 til 2024.\n",
    "\n",
    "Analysen retter fokus mot mulige strukturelle endringer rundt Russlands invasjon av Ukraina 24. februar 2022, som er markert i figurene."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf94914f",
   "metadata": {},
   "source": [
    "# Kravspesifikasjon\n",
    "\n",
    "For å sikre reproduserbarhet, anbefales det å benytte samme versjoner av alle biblioteker vedlagt i egen requirements.txt fil.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8da004-94dd-4296-bae3-3850f8492d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Importer nødvendige biblioteker ---\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import statsmodels\n",
    "import arch\n",
    "import matplotlib\n",
    "import plotly\n",
    "import openpyxl\n",
    "\n",
    "# Valgfritt: Importer notebook-spesifikke pakker dersom tilgjengelig\n",
    "try:\n",
    "    import notebook\n",
    "except ImportError:\n",
    "    notebook = None\n",
    "\n",
    "try:\n",
    "    import ipykernel\n",
    "except ImportError:\n",
    "    ipykernel = None\n",
    "\n",
    "# --- Samle versjonsinformasjon ---\n",
    "def get_versions():\n",
    "    \"\"\"Hent versjonsnummer for Python og relevante pakker.\"\"\"\n",
    "    versions = {\n",
    "        \"python\": f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\",\n",
    "        \"pandas\": pd.__version__,\n",
    "        \"numpy\": np.__version__,\n",
    "        \"scipy\": scipy.__version__,\n",
    "        \"statsmodels\": statsmodels.__version__,\n",
    "        \"arch\": arch.__version__,\n",
    "        \"matplotlib\": matplotlib.__version__,\n",
    "        \"plotly\": plotly.__version__,\n",
    "        \"openpyxl\": openpyxl.__version__,\n",
    "    }\n",
    "    if notebook:\n",
    "        versions[\"notebook\"] = notebook.__version__\n",
    "    if ipykernel:\n",
    "        versions[\"ipykernel\"] = ipykernel.__version__\n",
    "    return versions\n",
    "\n",
    "# --- Lagre kravspesifikasjon til requirements.txt ---\n",
    "def save_requirements(filename=\"requirements.txt\"):\n",
    "    \"\"\"Lagre alle pakkeversjoner til en requirements.txt-fil.\"\"\"\n",
    "    versions = get_versions()\n",
    "    with open(filename, \"w\") as f:\n",
    "        for package, version in versions.items():\n",
    "            f.write(f\"{package}=={version}\\n\")\n",
    "\n",
    "# --- Kjør lagring ---\n",
    "save_requirements()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eb31ff",
   "metadata": {},
   "source": [
    "# Importer biblioteker og definer konstanter\n",
    "\n",
    "Denne seksjonen laster inn nødvendige Python-biblioteker for dataanalyse, statistisk modellering, visualisering og eksport til Excel.  \n",
    "I tillegg defineres konstanter som brukes gjennom hele analysen:\n",
    "\n",
    "- Filbaner for input og output\n",
    "- Tidsperiode for analyse\n",
    "- Navnemapping for figurer\n",
    "- Datoe for invasjonen\n",
    "- Fargepalett for visualiseringer\n",
    "\n",
    "Mapper for lagring av resultater opprettes automatisk dersom de ikke eksisterer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dcd650-6bec-400d-8b98-c57123171dcc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# --- Importer nødvendige biblioteker ---\n",
    "\n",
    "# Standardbibliotek\n",
    "import os\n",
    "import re\n",
    "import inspect\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "\n",
    "# Tredjepartsbibliotek: Data og analyse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import skew, kurtosis, gaussian_kde, probplot\n",
    "\n",
    "# Tredjepartsbibliotek: Modellering og statistikk\n",
    "from arch import arch_model\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import het_arch, acorr_ljungbox\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "\n",
    "# Tredjepartsbibliotek: Visualisering\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display\n",
    "\n",
    "# Tredjepartsbibliotek: Excel-eksport\n",
    "from pandas import ExcelWriter\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.styles import Font, Border, Side\n",
    "\n",
    "# --- Konstanter: Filbaner ---\n",
    "INPUT_DIR = Path(\"input/daily_aggregate\")\n",
    "OUTPUT_DIR = Path(\"output\")\n",
    "EXCEL_DIR = OUTPUT_DIR / \"excel\"\n",
    "\n",
    "# Sørg for at output-mapper eksisterer\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "EXCEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Konstanter: Tidsperiode og parametere ---\n",
    "YEARS = range(2019, 2025)\n",
    "ROLLING_WINDOW = 30\n",
    "FIGURE_EXPORT_SCALE = 25\n",
    "\n",
    "# --- Konstanter: Navnemapping for figurer ---\n",
    "NAME_MAP = {\n",
    "    \"GER\": \"Tyskland\",\n",
    "    \"NO2\": \"Norge\"\n",
    "}\n",
    "\n",
    "# --- Viktige datoer (for analyse og figurer) ---\n",
    "BREAK_DATE = \"2022-02-24\"\n",
    "BREAK_DATE_LABEL = \"24. feb 2022\"\n",
    "BREAK_DATE_DT = pd.to_datetime(BREAK_DATE)\n",
    "\n",
    "# --- Fargepalett for visualisering ---\n",
    "COLOR_1 = \"#1f77b4\"  # blå\n",
    "COLOR_2 = \"#ff7f0e\"  # oransje\n",
    "COLOR_3 = \"#2ca02c\"  # grønn\n",
    "COLORS = [COLOR_1, COLOR_2, COLOR_3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf392a6-e540-466b-926a-81dee6c9a7cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# --- Felles layoutinnstillinger for Plotly-figurer ---\n",
    "common_layout: dict = {\n",
    "    \"template\": \"plotly_white\",\n",
    "    \"font\": {\n",
    "        \"family\": \"Times New Roman\",\n",
    "        \"size\": 16,\n",
    "        \"color\": \"black\",\n",
    "    },\n",
    "    \"margin\": {\n",
    "        \"l\": 80,\n",
    "        \"r\": 40,\n",
    "        \"t\": 80,\n",
    "        \"b\": 70,\n",
    "    },\n",
    "    \"legend\": {\n",
    "        \"title\": {\"text\": \"\"},\n",
    "        \"orientation\": \"h\",\n",
    "        \"yanchor\": \"bottom\",\n",
    "        \"y\": 1.02,\n",
    "        \"xanchor\": \"right\",\n",
    "        \"x\": 1,\n",
    "    },\n",
    "    \"hovermode\": \"x unified\",\n",
    "    \"xaxis\": {\n",
    "        \"showgrid\": True,\n",
    "        \"title_font\": {\n",
    "            \"size\": 16\n",
    "        },\n",
    "        \"tickfont\": {\n",
    "            \"size\": 14\n",
    "        },\n",
    "    },\n",
    "    \"yaxis\": {\n",
    "        \"showgrid\": True,\n",
    "        \"title_font\": {\n",
    "            \"size\": 16\n",
    "        },\n",
    "        \"tickfont\": {\n",
    "            \"size\": 14\n",
    "        },\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0655cf63",
   "metadata": {},
   "source": [
    "# Støttefunksjoner\n",
    "\n",
    "Her defineres nødvendige støttefunksjoner for analyse og presentasjon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33edbfe7-59f7-4ae6-9b71-05bf746fa53e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def add_break_line(\n",
    "    fig: go.Figure,\n",
    "    x: float,\n",
    "    label: str,\n",
    "    color: str = \"red\",\n",
    "    dash: str = \"dash\",\n",
    "    line_width: int = 2\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Legger til en vertikal linje i en Plotly-figur for å indikere et bruddpunkt.\n",
    "\n",
    "    Parametre:\n",
    "    ----------\n",
    "    fig : go.Figure\n",
    "        Plotly-figur som linjen skal legges til i.\n",
    "    x : float\n",
    "        X-posisjon for linjen (f.eks. dato eller tallverdi).\n",
    "    label : str\n",
    "        Navn som vises i figurens legend.\n",
    "    color : str, optional\n",
    "        Farge på linjen, som Plotly-fargenavn eller hex-kode. Standard er \"red\".\n",
    "    dash : str, optional\n",
    "        Linjetype (\"solid\", \"dash\", \"dot\"). Standard er \"dash\".\n",
    "    line_width : int, optional\n",
    "        Tykkelse på linjen. Standard er 2.\n",
    "\n",
    "    Returnerer:\n",
    "    -----------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Tegn vertikal linje ---\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=x, x1=x,\n",
    "        y0=0, y1=1,\n",
    "        xref=\"x\", yref=\"paper\",\n",
    "        line=dict(color=color, dash=dash, width=line_width),\n",
    "        layer=\"above\"\n",
    "    )\n",
    "\n",
    "    # --- Legg til dummy-trace for legend ---\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[None],\n",
    "            y=[None],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=color, dash=dash, width=line_width),\n",
    "            name=label,\n",
    "            hoverinfo=\"skip\",\n",
    "            showlegend=True\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb7d4ba-3ec8-47df-b7f5-c360a6faf8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries(\n",
    "    data: pd.DataFrame,\n",
    "    title: str,\n",
    "    y_title: str,\n",
    "    filename: str,\n",
    "    show: bool = True,\n",
    "    show_break: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Lager en linjegraf for én eller flere tidsserier.\n",
    "\n",
    "    Parametre:\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        DataFrame med datetime-indeks og én eller flere kolonner.\n",
    "    title : str\n",
    "        Tittel på figuren.\n",
    "    y_title : str\n",
    "        Y-akse tittel.\n",
    "    filename : str\n",
    "        Navn på filen figuren skal lagres som.\n",
    "    show : bool, optional\n",
    "        Om figuren skal vises etter lagring. Standard er True.\n",
    "    show_break : bool, optional\n",
    "        Om en vertikal bruddlinje skal legges til på BREAK_DATE_DT. Standard er False.\n",
    "\n",
    "    Returnerer:\n",
    "    -----------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Initialiser figur ---\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # --- Sjekk om data er tom ---\n",
    "    if data.empty:\n",
    "        print(\"Advarsel: Data er tom – ingen figur genereres.\")\n",
    "        return\n",
    "\n",
    "    # --- Legg til dataserier ---\n",
    "    if data.shape[1] == 1:\n",
    "        col = data.columns[0]\n",
    "        name = NAME_MAP.get(col, col)\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=data.index,\n",
    "                y=data[col],\n",
    "                name=name,\n",
    "                line=dict(color=COLORS[0]),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        for i, col in enumerate(data.columns):\n",
    "            name = NAME_MAP.get(col, col)\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=data.index,\n",
    "                    y=data[col],\n",
    "                    name=name,\n",
    "                    line=dict(color=COLORS[i % len(COLORS)]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # --- Legg til bruddlinje hvis ønskelig ---\n",
    "    if show_break:\n",
    "        add_break_line(fig, BREAK_DATE_DT, BREAK_DATE_LABEL)\n",
    "\n",
    "    # --- Oppdater layout ---\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        yaxis_title=y_title,\n",
    "        **common_layout\n",
    "    )\n",
    "\n",
    "    # --- Lagre figur ---\n",
    "    save_figure(fig, filename)\n",
    "\n",
    "    # --- Vis figur ---\n",
    "    if show:\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a489ab4-42c0-4744-b703-3bcc00884bd8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_scatter(\n",
    "    data: pd.DataFrame,\n",
    "    title: str,\n",
    "    y_title: str,\n",
    "    filename: str,\n",
    "    show: bool = True,\n",
    "    show_break: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Lager et scatter-plot for én eller flere tidsserier.\n",
    "\n",
    "    Parametre:\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        DataFrame med datetime-indeks og én eller flere kolonner.\n",
    "    title : str\n",
    "        Tittel på figuren.\n",
    "    y_title : str\n",
    "        Y-akse tittel.\n",
    "    filename : str\n",
    "        Navn på filen figuren skal lagres som.\n",
    "    show : bool, optional\n",
    "        Om figuren skal vises etter lagring. Standard er True.\n",
    "    show_break : bool, optional\n",
    "        Om dataserien skal deles opp før/etter BREAK_DATE_DT. Standard er False.\n",
    "\n",
    "    Returnerer:\n",
    "    -----------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Initialiser figur ---\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # --- Sjekk om data er tom ---\n",
    "    if data.empty:\n",
    "        print(\"Advarsel: Data er tom – ingen figur genereres.\")\n",
    "        return\n",
    "\n",
    "    # --- Legg til dataserier ---\n",
    "    if show_break and data.shape[1] == 1:\n",
    "        col = data.columns[0]\n",
    "        name = NAME_MAP.get(col, col)\n",
    "\n",
    "        pre_break = data.loc[data.index < BREAK_DATE_DT, col]\n",
    "        post_break = data.loc[data.index >= BREAK_DATE_DT, col]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=pre_break.index,\n",
    "                y=pre_break.values,\n",
    "                name=f\"{name} (før)\",\n",
    "                mode=\"markers\",\n",
    "                marker=dict(color=COLORS[0]),\n",
    "            )\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=post_break.index,\n",
    "                y=post_break.values,\n",
    "                name=f\"{name} (etter)\",\n",
    "                mode=\"markers\",\n",
    "                marker=dict(color=COLORS[1]),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        for i, col in enumerate(data.columns):\n",
    "            name = NAME_MAP.get(col, col)\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=data.index,\n",
    "                    y=data[col],\n",
    "                    name=name,\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(color=COLORS[i % len(COLORS)]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # --- Legg til bruddlinje hvis ønskelig ---\n",
    "    if show_break:\n",
    "        add_break_line(fig, BREAK_DATE_DT, BREAK_DATE_LABEL)\n",
    "\n",
    "    # --- Oppdater layout ---\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        yaxis_title=y_title,\n",
    "        **common_layout\n",
    "    )\n",
    "\n",
    "    # --- Lagre figur ---\n",
    "    save_figure(fig, filename)\n",
    "\n",
    "    # --- Vis figur ---\n",
    "    if show:\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1963355e-7fba-4469-8132-e7ffec410126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(\n",
    "    data: pd.DataFrame,\n",
    "    title: str,\n",
    "    x_title: str,\n",
    "    filename: str,\n",
    "    show: bool = True\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Lager histogram for én eller flere variabler.\n",
    "\n",
    "    Parametre:\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        DataFrame med én eller flere kolonner.\n",
    "    title : str\n",
    "        Tittel på figuren.\n",
    "    x_title : str\n",
    "        X-akse tittel.\n",
    "    filename : str\n",
    "        Navn på filen figuren skal lagres som.\n",
    "    show : bool, optional\n",
    "        Om figuren skal vises etter lagring. Standard er True.\n",
    "\n",
    "    Returnerer:\n",
    "    -----------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Initialiser figur ---\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # --- Sjekk om data er tom ---\n",
    "    if data.empty:\n",
    "        print(\"Advarsel: Data er tom – ingen histogram genereres.\")\n",
    "        return\n",
    "\n",
    "    # --- Legg til histogramspor ---\n",
    "    for i, col in enumerate(data.columns):\n",
    "        name = NAME_MAP.get(col, col)\n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=data[col],\n",
    "                name=name,\n",
    "                marker=dict(color=COLORS[i % len(COLORS)]),\n",
    "                opacity=0.75\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # --- Oppdater layout ---\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=x_title,\n",
    "        barmode=\"overlay\",\n",
    "        **common_layout\n",
    "    )\n",
    "\n",
    "    # --- Lagre figur ---\n",
    "    save_figure(fig, filename)\n",
    "\n",
    "    # --- Vis figur ---\n",
    "    if show:\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeff3e4c-a835-4f56-8168-e22645e3d1ab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_rolling_average(\n",
    "    data: pd.DataFrame,\n",
    "    title: str,\n",
    "    y_title: str,\n",
    "    filename: str,\n",
    "    window: int = ROLLING_WINDOW,\n",
    "    show: bool = True,\n",
    "    show_break: bool = True\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plotter glidende gjennomsnitt av én eller flere tidsserier.\n",
    "\n",
    "    Parametre:\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        DataFrame med datetime-indeks og én eller flere kolonner.\n",
    "    title : str\n",
    "        Tittel på figuren.\n",
    "    y_title : str\n",
    "        Y-akse tittel.\n",
    "    filename : str\n",
    "        Navn på filen figuren skal lagres som.\n",
    "    window : int, optional\n",
    "        Lengde på det glidende vinduet. Standard er ROLLING_WINDOW.\n",
    "    show : bool, optional\n",
    "        Om figuren skal vises etter lagring. Standard er True.\n",
    "    show_break : bool, optional\n",
    "        Om en bruddlinje skal legges til. Standard er True.\n",
    "\n",
    "    Returnerer:\n",
    "    -----------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Sjekk om data er tom ---\n",
    "    if data.empty:\n",
    "        print(\"Advarsel: Data er tom – glidende gjennomsnitt ikke generert.\")\n",
    "        return\n",
    "\n",
    "    # --- Beregn glidende gjennomsnitt ---\n",
    "    rolling_data = data.rolling(window=window, min_periods=1).mean()\n",
    "\n",
    "    # --- Plot glidende gjennomsnitt ---\n",
    "    plot_timeseries(\n",
    "        rolling_data,\n",
    "        title=title,\n",
    "        y_title=y_title,\n",
    "        filename=filename,\n",
    "        show=show,\n",
    "        show_break=show_break\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb481ef-fb74-47d2-b162-70d3b7d7b89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram_comparison(\n",
    "    series1: pd.Series,\n",
    "    series2: pd.Series,\n",
    "    label1: str,\n",
    "    label2: str,\n",
    "    title: str,\n",
    "    xlabel: str,\n",
    "    filename: str,\n",
    "    bins: int = 40,\n",
    "    show: bool = True\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plotter to distribusjoner med histogram, KDE og gjennomsnittslinjer.\n",
    "    Legenden viser gjennomsnitt og plasseres under plottet.\n",
    "\n",
    "    Parametre:\n",
    "    ----------\n",
    "    series1, series2 : pd.Series\n",
    "        Pandas Series med verdier.\n",
    "    label1, label2 : str\n",
    "        Navn for dataseriene.\n",
    "    title : str\n",
    "        Tittel på figuren.\n",
    "    xlabel : str\n",
    "        Navn på x-aksen.\n",
    "    filename : str\n",
    "        Navn på filen figuren skal lagres som.\n",
    "    bins : int, optional\n",
    "        Antall søyler i histogrammet. Standard er 40.\n",
    "    show : bool, optional\n",
    "        Om figuren skal vises etter lagring. Standard er True.\n",
    "\n",
    "    Returnerer:\n",
    "    -----------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Bruk mapping på etiketter ---\n",
    "    label1_mapped = NAME_MAP.get(label1, label1)\n",
    "    label2_mapped = NAME_MAP.get(label2, label2)\n",
    "\n",
    "    # --- Beregn statistikk ---\n",
    "    mean1, mean2 = series1.mean(), series2.mean()\n",
    "    kde1, kde2 = gaussian_kde(series1), gaussian_kde(series2)\n",
    "\n",
    "    # --- Definer x-akse for KDE ---\n",
    "    x_range = np.linspace(\n",
    "        min(series1.min(), series2.min()),\n",
    "        max(series1.max(), series2.max()),\n",
    "        500\n",
    "    )\n",
    "\n",
    "    # --- Definer visningsområde (±3 std) ---\n",
    "    combined = np.concatenate([series1, series2])\n",
    "    mean_comb = combined.mean()\n",
    "    std_comb = combined.std()\n",
    "    x_min, x_max = mean_comb - 3 * std_comb, mean_comb + 3 * std_comb\n",
    "\n",
    "    # --- Initialiser figur ---\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # --- Legg til histogrammer ---\n",
    "    for series, label, color in [\n",
    "        (series1, label1_mapped, COLOR_1),\n",
    "        (series2, label2_mapped, COLOR_2)\n",
    "    ]:\n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=series,\n",
    "                name=label,\n",
    "                marker_color=color,\n",
    "                opacity=0.6,\n",
    "                nbinsx=bins,\n",
    "                histnorm=\"probability density\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # --- Legg til KDE-linjer ---\n",
    "    for kde, mean, label, color in [\n",
    "        (kde1, mean1, label1_mapped, COLOR_1),\n",
    "        (kde2, mean2, label2_mapped, COLOR_2)\n",
    "    ]:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x_range,\n",
    "                y=kde(x_range),\n",
    "                mode=\"lines\",\n",
    "                name=f\"KDE {label} (μ = {mean:.2f})\",\n",
    "                line=dict(color=color)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # --- Legg til vertikale gjennomsnittslinjer ---\n",
    "    for mean, color in [(mean1, COLOR_1), (mean2, COLOR_2)]:\n",
    "        fig.add_vline(\n",
    "            x=mean,\n",
    "            line=dict(color=color, dash=\"dash\")\n",
    "        )\n",
    "\n",
    "    # --- Sett opp layout ---\n",
    "    layout = common_layout.copy()\n",
    "    layout.update({\n",
    "        \"title\": title,\n",
    "        \"xaxis_title\": xlabel,\n",
    "        \"yaxis_title\": \"Tetthet\",\n",
    "        \"barmode\": \"overlay\",\n",
    "        \"xaxis\": {**common_layout[\"xaxis\"], \"range\": [x_min, x_max]},\n",
    "        \"legend\": dict(\n",
    "            orientation=\"h\",\n",
    "            x=0.5,\n",
    "            y=-0.3,\n",
    "            xanchor=\"center\",\n",
    "            yanchor=\"top\",\n",
    "            font=dict(size=13)\n",
    "        ),\n",
    "        \"margin\": dict(l=80, r=40, t=80, b=120)\n",
    "    })\n",
    "\n",
    "    fig.update_layout(**layout)\n",
    "\n",
    "    # --- Lagre figur ---\n",
    "    save_figure(fig, filename)\n",
    "\n",
    "    # --- Vis figur ---\n",
    "    if show:\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a63b6b-c8d1-499c-b6f6-203738de6a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_qq(\n",
    "    data: pd.Series,\n",
    "    label: str,\n",
    "    color: str,\n",
    "    title: str,\n",
    "    filename: str,\n",
    "    show: bool = True\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Lager QQ-plott mot normalfordeling.\n",
    "\n",
    "    Parametre:\n",
    "    ----------\n",
    "    data : pd.Series\n",
    "        Pandas Series med data som skal sammenlignes med normalfordeling.\n",
    "    label : str\n",
    "        Navn som vises i figuren.\n",
    "    color : str\n",
    "        Farge på datapunktene.\n",
    "    title : str\n",
    "        Tittel på figuren.\n",
    "    filename : str\n",
    "        Navn på filen figuren skal lagres som.\n",
    "    show : bool, optional\n",
    "        Om figuren skal vises etter lagring. Standard er True.\n",
    "\n",
    "    Returnerer:\n",
    "    -----------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Sjekk om data er tom ---\n",
    "    if data.empty:\n",
    "        print(\"Advarsel: Data er tom – QQ-plot ikke generert.\")\n",
    "        return\n",
    "\n",
    "    # --- Beregn teoretiske og observerte kvantiler ---\n",
    "    (osm, osr), (slope, intercept, _) = probplot(data, dist=\"norm\")\n",
    "\n",
    "    line_x = np.array([osm.min(), osm.max()])\n",
    "    line_y = slope * line_x + intercept\n",
    "\n",
    "    # --- Initialiser figur ---\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # --- Legg til datapunkter ---\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=osm,\n",
    "            y=osr,\n",
    "            mode=\"markers\",\n",
    "            name=label,\n",
    "            marker=dict(color=color)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # --- Legg til referanselinje ---\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=line_x,\n",
    "            y=line_y,\n",
    "            mode=\"lines\",\n",
    "            name=\"Normal linje\",\n",
    "            line=dict(color=\"black\", dash=\"dash\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # --- Oppdater layout ---\n",
    "    fig.update_layout(\n",
    "        title=f\"{title} {label}\",\n",
    "        xaxis_title=\"Teoretiske kvantiler\",\n",
    "        yaxis_title=\"Observerte verdier\",\n",
    "        showlegend=False,\n",
    "        **common_layout\n",
    "    )\n",
    "\n",
    "    # --- Lagre figur ---\n",
    "    save_figure(fig, filename)\n",
    "\n",
    "    # --- Vis figur ---\n",
    "    if show:\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fb7d41-dbd2-4cfb-9061-8523428ed921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acf_pacf(\n",
    "    series: pd.Series,\n",
    "    title_prefix: str = \"\",\n",
    "    lags: int = 20,\n",
    "    show: bool = True\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Lager ACF- og PACF-plot for en gitt tidsserie, med 95 % konfidensintervall.\n",
    "\n",
    "    Parametre:\n",
    "    ----------\n",
    "    series : pd.Series\n",
    "        Tidsserie som skal analyseres.\n",
    "    title_prefix : str, optional\n",
    "        Prefiks som brukes i titler og filnavn. Standard er tom streng.\n",
    "    lags : int, optional\n",
    "        Antall lag som skal beregnes. Standard er 20.\n",
    "    show : bool, optional\n",
    "        Om figurene skal vises etter lagring. Standard er True.\n",
    "\n",
    "    Returnerer:\n",
    "    -----------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Beregn konfidensintervall ---\n",
    "    n = len(series.dropna())\n",
    "    conf_int = 1.96 / np.sqrt(n)\n",
    "\n",
    "    # --- Beregn ACF og PACF ---\n",
    "    acf_vals = acf(series, nlags=lags)\n",
    "    pacf_vals = pacf(series, nlags=lags)\n",
    "    x_vals = list(range(len(acf_vals)))\n",
    "\n",
    "    # --- Definer annotasjon ---\n",
    "    annotation_text = \"Streken viser 95 % konfidensintervall for nullhypotesen (ingen autokorrelasjon)\"\n",
    "    annotation = dict(\n",
    "        text=annotation_text,\n",
    "        xref=\"paper\",\n",
    "        yref=\"paper\",\n",
    "        x=0,\n",
    "        y=-0.20,\n",
    "        showarrow=False,\n",
    "        font=dict(size=12, color=\"gray\"),\n",
    "        align=\"left\"\n",
    "    )\n",
    "\n",
    "    # --- Lag ACF-figur ---\n",
    "    acf_fig = go.Figure()\n",
    "    acf_fig.add_trace(\n",
    "        go.Bar(x=x_vals, y=acf_vals, name=\"ACF\")\n",
    "    )\n",
    "    acf_fig.add_shape(\n",
    "        type=\"rect\",\n",
    "        x0=-0.5, x1=lags + 0.5,\n",
    "        y0=-conf_int, y1=conf_int,\n",
    "        fillcolor=\"lightblue\",\n",
    "        opacity=0.3,\n",
    "        layer=\"below\",\n",
    "        line_width=0\n",
    "    )\n",
    "    acf_fig.add_hline(y=conf_int, line=dict(dash=\"dash\", color=\"blue\"), opacity=0.5)\n",
    "    acf_fig.add_hline(y=-conf_int, line=dict(dash=\"dash\", color=\"blue\"), opacity=0.5)\n",
    "    acf_fig.update_layout(\n",
    "        title=f\"{title_prefix} ACF\",\n",
    "        xaxis_title=\"Lag\",\n",
    "        yaxis_title=\"Autokorrelasjon\",\n",
    "        annotations=[annotation],\n",
    "        **common_layout\n",
    "    )\n",
    "\n",
    "    # --- Lag PACF-figur ---\n",
    "    pacf_fig = go.Figure()\n",
    "    pacf_fig.add_trace(\n",
    "        go.Bar(x=x_vals, y=pacf_vals, name=\"PACF\")\n",
    "    )\n",
    "    pacf_fig.add_shape(\n",
    "        type=\"rect\",\n",
    "        x0=-0.5, x1=lags + 0.5,\n",
    "        y0=-conf_int, y1=conf_int,\n",
    "        fillcolor=\"lightblue\",\n",
    "        opacity=0.3,\n",
    "        layer=\"below\",\n",
    "        line_width=0\n",
    "    )\n",
    "    pacf_fig.add_hline(y=conf_int, line=dict(dash=\"dash\", color=\"blue\"), opacity=0.5)\n",
    "    pacf_fig.add_hline(y=-conf_int, line=dict(dash=\"dash\", color=\"blue\"), opacity=0.5)\n",
    "    pacf_fig.update_layout(\n",
    "        title=f\"{title_prefix} PACF\",\n",
    "        xaxis_title=\"Lag\",\n",
    "        yaxis_title=\"Partial Autokorrelasjon\",\n",
    "        annotations=[annotation],\n",
    "        **common_layout\n",
    "    )\n",
    "\n",
    "    # --- Lagre figurer ---\n",
    "    save_figure(acf_fig, f\"{title_prefix}_acf\")\n",
    "    save_figure(pacf_fig, f\"{title_prefix}_pacf\")\n",
    "\n",
    "    # --- Vis figurer ---\n",
    "    if show:\n",
    "        acf_fig.show()\n",
    "        pacf_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d64e46-e1c2-499d-9159-142f5372bf7a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def save_figure(fig: go.Figure, name: str) -> None:\n",
    "    \"\"\"\n",
    "    Lagrer en Plotly-figur som HTML, PDF og PNG i organiserte undermapper.\n",
    "\n",
    "    Parametre:\n",
    "    ----------\n",
    "    fig : go.Figure\n",
    "        Plotly-figur som skal lagres.\n",
    "    name : str\n",
    "        Filnavn uten filtype (brukes som base for alle formater).\n",
    "\n",
    "    Returnerer:\n",
    "    -----------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Definer undermapper og filstier ---\n",
    "    formats = [\"html\", \"pdf\", \"png\"]\n",
    "    paths = {\n",
    "        fmt: os.path.join(OUTPUT_DIR, fmt, f\"{name}.{fmt}\")\n",
    "        for fmt in formats\n",
    "    }\n",
    "\n",
    "    # --- Opprett mapper om nødvendig ---\n",
    "    for fmt in formats:\n",
    "        os.makedirs(os.path.join(OUTPUT_DIR, fmt), exist_ok=True)\n",
    "\n",
    "    # --- Intern hjelpefunksjon for trygg lagring ---\n",
    "    def _safe_write(write_func, path: str, label: str) -> None:\n",
    "        try:\n",
    "            write_func(path)\n",
    "        except Exception as e:\n",
    "            print(f\"Kunne ikke lagre {label} for {name}: {e}\")\n",
    "\n",
    "    # --- Lagre som HTML ---\n",
    "    _safe_write(fig.write_html, paths[\"html\"], \"HTML\")\n",
    "\n",
    "    # --- Lagre som PDF og PNG ---\n",
    "    for fmt in [\"pdf\", \"png\"]:\n",
    "        _safe_write(\n",
    "            lambda p: fig.write_image(p, scale=FIGURE_EXPORT_SCALE),\n",
    "            paths[fmt],\n",
    "            fmt.upper()\n",
    "        )\n",
    "\n",
    "    # --- Registrer figur hvis funksjon finnes ---\n",
    "    try:\n",
    "        add_figure(name, fig)\n",
    "    except NameError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993ea741-9bce-4dfb-8bbd-899656607a7c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def save_to_excel(\n",
    "    excel_path: Path = Path(\"output/excel/data_series.xlsx\"),\n",
    "    **kwargs\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Lagrer ett eller flere objekter til en Excel-fil.\n",
    "\n",
    "    - DataFrames lagres på egne arkfaner med variabelnavn som arknavn.\n",
    "    - Andre objekter lagres i et sammendrag i et ark kalt \"variables\".\n",
    "\n",
    "    Parametre:\n",
    "    ----------\n",
    "    excel_path : Path, optional\n",
    "        Filsti til Excel-filen. Standard er \"output/excel/data_series.xlsx\".\n",
    "    kwargs : key-value\n",
    "        Navn og objekter som skal lagres.\n",
    "\n",
    "    Returnerer:\n",
    "    -----------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    from openpyxl import load_workbook\n",
    "\n",
    "    # --- Sørg for at mappe eksisterer ---\n",
    "    excel_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # --- Opprett fil om den ikke eksisterer ---\n",
    "    if not excel_path.exists():\n",
    "        with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "            pd.DataFrame([[\"Midlertidig ark, kan slettes.\"]]).to_excel(writer, sheet_name=\"temp\")\n",
    "\n",
    "    # --- Registrer eksisterende ark ---\n",
    "    existing_sheets = set()\n",
    "    if excel_path.exists():\n",
    "        wb = load_workbook(excel_path)\n",
    "        existing_sheets = set(wb.sheetnames)\n",
    "\n",
    "    variables_info = {}\n",
    "\n",
    "    # --- Lagre objektene ---\n",
    "    with pd.ExcelWriter(excel_path, mode=\"a\", engine=\"openpyxl\", if_sheet_exists=\"replace\") as writer:\n",
    "        for var_name, obj in kwargs.items():\n",
    "            sheet_name = var_name[:31]  # Excel-begrensning på arkfanenavn\n",
    "\n",
    "            if isinstance(obj, pd.DataFrame):\n",
    "                try:\n",
    "                    obj.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "                except Exception as e:\n",
    "                    print(f\"Kunne ikke lagre DataFrame '{var_name}': {e}\")\n",
    "            else:\n",
    "                # Lag et sammendrag for ikke-DataFrame objekter\n",
    "                summary = str(obj)[:100]\n",
    "                variables_info[var_name] = {\n",
    "                    \"Variable\": var_name,\n",
    "                    \"Type\": type(obj).__name__,\n",
    "                    \"Value\": summary\n",
    "                }\n",
    "\n",
    "        # --- Lagre sammendrag dersom andre objekter finnes ---\n",
    "        if variables_info:\n",
    "            var_df = pd.DataFrame(variables_info.values())\n",
    "            try:\n",
    "                var_df.to_excel(writer, sheet_name=\"variables\", index=False)\n",
    "            except Exception as e:\n",
    "                print(f\"Kunne ikke lagre 'variables'-arket: {e}\")\n",
    "\n",
    "    # --- Ferdig ---\n",
    "    print(f\"Alt er lagret i Excel: {excel_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac443a0-3a80-450a-9e90-6ab3b4b965ad",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def save_garch_summaries_txt(\n",
    "    garch_models: dict,\n",
    "    txt_path: str = \"output/garch_summaries.txt\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Lagrer sammendrag fra GARCH-modeller til en tekstfil.\n",
    "\n",
    "    Parametre:\n",
    "    ----------\n",
    "    garch_models : dict\n",
    "        Ordbok med nøkler (str) og verdier (fitted GARCH-modeller med .summary()-metode).\n",
    "    txt_path : str, optional\n",
    "        Filsti for lagring. Standard er \"output/garch_summaries.txt\".\n",
    "\n",
    "    Returnerer:\n",
    "    -----------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # --- Sørg for at mappe eksisterer ---\n",
    "        os.makedirs(os.path.dirname(txt_path), exist_ok=True)\n",
    "\n",
    "        # --- Skriv sammendrag til tekstfil ---\n",
    "        with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for key, model in garch_models.items():\n",
    "                f.write(f\"{'=' * 40}\\n\")\n",
    "                f.write(f\"GARCH Model for: {key}\\n\")\n",
    "                f.write(f\"{'-' * 40}\\n\")\n",
    "                f.write(model.summary().as_text())\n",
    "                f.write(\"\\n\\n\")\n",
    "\n",
    "        print(f\"GARCH-sammendrag lagret til: {txt_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Kunne ikke lagre GARCH-sammendrag: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57bb924-16b8-4118-a073-b56714979c14",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def export_garch_results_to_excel(\n",
    "    results_dict: dict,\n",
    "    filename: str = \"data.xlsx\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Eksporterer GARCH-modellresultater til en Excel-fil med formatert tabell på norsk.\n",
    "\n",
    "    Parametre:\n",
    "    ----------\n",
    "    results_dict : dict\n",
    "        Dictionary med modellresultater, f.eks. {\"GER\": result1, \"NO2\": result2}.\n",
    "    filename : str, optional\n",
    "        Navn på Excel-filen. Standard er \"data.xlsx\".\n",
    "\n",
    "    Returnerer:\n",
    "    -----------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Definer filsti ---\n",
    "    file_path = EXCEL_DIR / filename\n",
    "\n",
    "    summary_rows = {}\n",
    "    temp_writer_data = {}\n",
    "\n",
    "    # --- Behandle hver modell ---\n",
    "    for code, result in results_dict.items():\n",
    "        country = NAME_MAP.get(code, code)\n",
    "        sheet_name = f\"EGARCH-modell for {country}\"\n",
    "\n",
    "        # Hent modellresultater\n",
    "        params = result.params\n",
    "        stderr = result.std_err\n",
    "        tvals = result.tvalues\n",
    "        pvals = result.pvalues\n",
    "        conf_int = result.conf_int()\n",
    "\n",
    "        # Formater rader for Excel\n",
    "        formatted_rows = []\n",
    "        for param in params.index:\n",
    "            # Kategoriser parameter\n",
    "            if param == \"mu\":\n",
    "                section = \"Gjennomsnittsmodell\"\n",
    "            elif param.startswith(\"nu\"):\n",
    "                section = \"Distribusjon\"\n",
    "            else:\n",
    "                section = \"Volatilitetsmodell\"\n",
    "\n",
    "            coef = params[param]\n",
    "            se = stderr[param]\n",
    "            tval = tvals[param]\n",
    "            pval = pvals[param]\n",
    "            ci_low, ci_high = conf_int.loc[param]\n",
    "\n",
    "            formatted_rows.append([\n",
    "                section,\n",
    "                param,\n",
    "                f\"{coef:.4f}\",\n",
    "                f\"{se:.4f}\",\n",
    "                f\"{tval:.4f}\",\n",
    "                f\"{pval:.4f}\",\n",
    "                f\"[{ci_low:.4f}, {ci_high:.4f}]\"\n",
    "            ])\n",
    "\n",
    "        df_formatted = pd.DataFrame(\n",
    "            formatted_rows,\n",
    "            columns=[\n",
    "                \"Modellkomponent\", \"Parameter\", \"Estimat\",\n",
    "                \"Standardfeil\", \"t-verdi\", \"p-verdi\", \"95 % konfidensintervall\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        temp_writer_data[sheet_name[:31]] = df_formatted\n",
    "\n",
    "        # Legg til informasjon for sammendrag\n",
    "        model = result.model\n",
    "        summary_rows[code] = {\n",
    "            \"Land\": country,\n",
    "            \"Volatilitetsmodell\": model.volatility.__class__.__name__,\n",
    "            \"Distribusjon\": model.distribution.name,\n",
    "            \"AIC\": round(result.aic, 4),\n",
    "            \"BIC\": round(result.bic, 4),\n",
    "            \"Log-likelihood\": round(result.loglikelihood, 4)\n",
    "        }\n",
    "\n",
    "    # --- Opprett sammendrag DataFrame ---\n",
    "    df_summary = pd.DataFrame(summary_rows.values())\n",
    "    df_summary = df_summary[[\n",
    "        \"Land\", \"Volatilitetsmodell\", \"Distribusjon\", \"AIC\", \"BIC\", \"Log-likelihood\"\n",
    "    ]]\n",
    "\n",
    "    # --- Skriv til Excel ---\n",
    "    with pd.ExcelWriter(file_path, engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "        for sheet, df in temp_writer_data.items():\n",
    "            df.to_excel(writer, sheet_name=sheet, index=False)\n",
    "        df_summary.to_excel(writer, sheet_name=\"GARCH-sammendrag\", index=False)\n",
    "\n",
    "    # --- Ferdig ---\n",
    "    print(f\"GARCH-resultater lagret som faner i: {file_path.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19560c92-473d-4e4c-886a-b83a913daf4a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def test_egarch_variants(\n",
    "    series: pd.Series,\n",
    "    distributions: list = [\"normal\", \"t\", \"skewt\"]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Estimerer EGARCH-modeller for en gitt serie over ulike (p, q)-kombinasjoner og fordelinger.\n",
    "\n",
    "    Parametre:\n",
    "    ----------\n",
    "    series : pd.Series\n",
    "        Stasjonær inputserie (f.eks. differensierte priser).\n",
    "    distributions : list, optional\n",
    "        Liste over fordelinger som skal testes (f.eks. [\"t\", \"skewt\"]). Standard er [\"normal\", \"t\", \"skewt\"].\n",
    "\n",
    "    Returnerer:\n",
    "    -----------\n",
    "    pd.DataFrame\n",
    "        DataFrame med p, q, fordeling, AIC, BIC og log-likelihood, sortert etter AIC.\n",
    "    \"\"\"\n",
    "\n",
    "    from arch import arch_model\n",
    "\n",
    "    # --- Definer (p, q)-kombinasjoner ---\n",
    "    p_q_combos = [(1, 1), (1, 2), (2, 1), (2, 2)]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # --- Estimer modeller ---\n",
    "    for p, q in p_q_combos:\n",
    "        for dist in distributions:\n",
    "            try:\n",
    "                model = arch_model(series, vol=\"EGARCH\", p=p, q=q, dist=dist)\n",
    "                res = model.fit(disp=\"off\")\n",
    "\n",
    "                results.append({\n",
    "                    \"p\": p,\n",
    "                    \"q\": q,\n",
    "                    \"dist\": dist,\n",
    "                    \"loglikelihood\": res.loglikelihood,\n",
    "                    \"aic\": res.aic,\n",
    "                    \"bic\": res.bic\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Feil med EGARCH({p},{q}) - {dist}: {e}\")\n",
    "\n",
    "    # --- Returner resultater som DataFrame ---\n",
    "    return pd.DataFrame(results).sort_values(\"aic\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0197ef02-714b-4540-a03b-b2560dde315b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_daily_prices(\n",
    "    years: list[int],\n",
    "    input_dir: Path,\n",
    "    columns_to_keep: list[str]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Leser inn og samler daglige prisdata for oppgitte år.\n",
    "\n",
    "    Parametre:\n",
    "    ----------\n",
    "    years : list[int]\n",
    "        Liste over årstall som skal leses inn.\n",
    "    input_dir : Path\n",
    "        Mappe hvor CSV-filene ligger.\n",
    "    columns_to_keep : list[str]\n",
    "        Liste over kolonner som skal beholdes fra hver fil.\n",
    "\n",
    "    Returnerer:\n",
    "    -----------\n",
    "    pd.DataFrame\n",
    "        Samlet og renset DataFrame med dato som indeks.\n",
    "    \"\"\"\n",
    "\n",
    "    dataframes = []\n",
    "    missing_years = []\n",
    "\n",
    "    # --- Les inn hvert år ---\n",
    "    for year in years:\n",
    "        file_path = input_dir / f\"daily_aggregate_{year}.csv\"\n",
    "\n",
    "        if file_path.exists():\n",
    "            df = pd.read_csv(\n",
    "                file_path,\n",
    "                delimiter=\";\",\n",
    "                decimal=\",\",\n",
    "                thousands=\".\"\n",
    "            )\n",
    "            df[\"Delivery Date CET\"] = pd.to_datetime(df[\"Delivery Date CET\"])\n",
    "            dataframes.append(df)\n",
    "        else:\n",
    "            missing_years.append(year)\n",
    "\n",
    "    # --- Sjekk at filer er funnet ---\n",
    "    if not dataframes:\n",
    "        raise FileNotFoundError(\"Ingen CSV-filer ble funnet i input-mappen.\")\n",
    "\n",
    "    if missing_years:\n",
    "        print(f\"Følgende år manglet filer og ble hoppet over: {missing_years}\")\n",
    "\n",
    "    # --- Slå sammen og bearbeid ---\n",
    "    combined = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Rens kolonnenavn\n",
    "    combined.columns = [col.replace(\" (EUR)\", \"\") for col in combined.columns]\n",
    "\n",
    "    # Behold kun nødvendige kolonner og fjern NA\n",
    "    combined = combined[columns_to_keep].dropna()\n",
    "\n",
    "    # Sett dato som indeks og sorter\n",
    "    combined.set_index(\"Delivery Date CET\", inplace=True)\n",
    "    combined.sort_index(inplace=True)\n",
    "\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db841ff8-1a62-4fd8-a2a9-7b15a7f6fd1f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# --- Definer kolonner som skal beholdes ---\n",
    "columns_to_keep = [\"Delivery Date CET\", \"GER\", \"NO2\"]\n",
    "\n",
    "# --- Les inn daglige priser ---\n",
    "daily_prices = load_daily_prices(\n",
    "    years=YEARS,\n",
    "    input_dir=INPUT_DIR,\n",
    "    columns_to_keep=columns_to_keep\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d4b54-788a-4d25-bc4f-c6fa8ce52238",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def descriptive_analysis(\n",
    "    data: pd.DataFrame,\n",
    "    filnavn: str = \"output/excel/data.xlsx\",\n",
    "    prefix: str = None,\n",
    "    break_date: pd.Timestamp = pd.Timestamp(\"2022-02-24\")\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Utfører deskriptiv analyse og lagrer resultatene i én Excel-fane,\n",
    "    med separate overskrifter for hele perioden, før og etter bruddet.\n",
    "\n",
    "    Parametre:\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Inndata med datetime-indeks.\n",
    "    filnavn : str, optional\n",
    "        Sti til Excel-filen hvor resultatene skal lagres. Standard er \"output/excel/data.xlsx\".\n",
    "    prefix : str, optional\n",
    "        Prefix for navnet på Excel-arket. Hvis None, brukes variabelnavnet automatisk.\n",
    "    break_date : pd.Timestamp, optional\n",
    "        Dato for bruddpunktet (default = 24. februar 2022).\n",
    "\n",
    "    Returnerer:\n",
    "    -----------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    from openpyxl import load_workbook\n",
    "\n",
    "    # --- Sett opp prefix om nødvendig ---\n",
    "    if prefix is None:\n",
    "        callers_local_vars = inspect.currentframe().f_back.f_locals.items()\n",
    "        prefix = next((name for name, val in callers_local_vars if val is data), 'data')\n",
    "        prefix += \"_stats\"\n",
    "\n",
    "    # --- Del opp datasettet ---\n",
    "    parts = {\n",
    "        \"HELE PERIODEN\": data,\n",
    "        \"FØR INVASJONEN\": data[data.index < break_date],\n",
    "        \"ETTER INVASJONEN\": data[data.index >= break_date],\n",
    "    }\n",
    "\n",
    "    output_path = Path(filnavn)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # --- Opprett fil om den ikke eksisterer ---\n",
    "    if not output_path.exists():\n",
    "        with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "            pd.DataFrame([[\"Midlertidig ark, kan slettes.\"]]).to_excel(writer, sheet_name=\"temp\")\n",
    "\n",
    "    arkfane = prefix[:31]\n",
    "    startrow = 0\n",
    "\n",
    "    # --- Skriv analyser til Excel ---\n",
    "    with pd.ExcelWriter(output_path, mode=\"a\", engine=\"openpyxl\", if_sheet_exists=\"overlay\") as writer:\n",
    "        for delnavn, subset in parts.items():\n",
    "            description = []\n",
    "\n",
    "            for col in subset.columns:\n",
    "                serie = subset[col].dropna()\n",
    "                if serie.empty:\n",
    "                    continue\n",
    "\n",
    "                q1 = serie.quantile(0.25)\n",
    "                q3 = serie.quantile(0.75)\n",
    "\n",
    "                description.append({\n",
    "                    \"Serie\": col,\n",
    "                    \"Minimum\": serie.min(),\n",
    "                    \"1. kvartil\": q1,\n",
    "                    \"Median\": serie.median(),\n",
    "                    \"3. kvartil\": q3,\n",
    "                    \"Maksimum\": serie.max(),\n",
    "                    \"Gjennomsnitt\": serie.mean(),\n",
    "                    \"Standardavvik\": serie.std(),\n",
    "                    \"Skjevhet\": skew(serie, bias=False),\n",
    "                    \"Kurtosis\": kurtosis(serie, fisher=True, bias=False),\n",
    "                })\n",
    "\n",
    "                print(f\"- Serie: {col:<10} | Periode: {delnavn:<13} | Antall obs: {len(serie)}\")\n",
    "\n",
    "            df_description = pd.DataFrame(description).round(2)\n",
    "\n",
    "            # Skriv tittel og data\n",
    "            pd.DataFrame([[delnavn]]).to_excel(\n",
    "                writer,\n",
    "                sheet_name=arkfane,\n",
    "                startrow=startrow,\n",
    "                startcol=0,\n",
    "                index=False,\n",
    "                header=False\n",
    "            )\n",
    "\n",
    "            df_description.to_excel(\n",
    "                writer,\n",
    "                sheet_name=arkfane,\n",
    "                startrow=startrow,\n",
    "                startcol=1,\n",
    "                index=False\n",
    "            )\n",
    "\n",
    "            startrow += len(df_description) + 3\n",
    "\n",
    "    # --- Formatering med openpyxl ---\n",
    "    wb = load_workbook(output_path)\n",
    "    ws = wb[arkfane]\n",
    "    bold_font = Font(bold=True)\n",
    "\n",
    "    # Sett fet skrift på deloverskrifter\n",
    "    for row in ws.iter_rows(min_row=1, max_row=startrow):\n",
    "        if row[0].value in parts.keys():\n",
    "            row[0].font = bold_font\n",
    "\n",
    "    # Juster kolonnebredder\n",
    "    for col in ws.columns:\n",
    "        max_length = 0\n",
    "        column = col[0].column_letter\n",
    "        for cell in col:\n",
    "            if cell.value is not None:\n",
    "                try:\n",
    "                    max_length = max(max_length, len(str(cell.value)))\n",
    "                except Exception:\n",
    "                    pass\n",
    "        adjusted_width = max_length + 2\n",
    "        ws.column_dimensions[column].width = adjusted_width\n",
    "\n",
    "    # --- Lagre fil ---\n",
    "    wb.save(output_path)\n",
    "\n",
    "    print(f\"\\nDeskriptiv analyse samlet i én fane: '{arkfane}' i filen {filnavn}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0facd9-cecf-427a-a99d-28693610479a",
   "metadata": {},
   "source": [
    "# DCC-modellen: Fra teori til kode\n",
    "\n",
    "Vi viser her hvordan variablene i DCC-modellen (slik den er definert i V-Lab-dokumentasjonen) samsvarer med variablene i vårt eget datasett og kode.\n",
    "\n",
    "📄 Teori og dokumentasjon:  \n",
    "https://vlab.stern.nyu.edu/docs/correlation/GARCH-DCC\n",
    "\n",
    "\n",
    "---\n",
    "## Differensiert serie brukt i modellen\n",
    "\n",
    "Differansen $\\Delta s_t$ brukes som erstatning for log-avkastning:\n",
    "\n",
    "$$\n",
    "\\Delta s_t = s_t - s_{t-1}\n",
    "$$\n",
    "\n",
    "**Kode:**\n",
    "```python\n",
    "transformed_diff = transformed_prices.diff().dropna()\n",
    "```\n",
    "\n",
    "Dette tilsvarer modellen:\n",
    "\n",
    "$$\n",
    "r_t = \\mu_t + \\varepsilon_t\n",
    "$$\n",
    "\n",
    "Hvor $\\mu_t \\approx 0 $, og $ \\varepsilon_t $ estimeres videre med GARCH.\n",
    "\n",
    "---\n",
    "\n",
    "## EGARCH-estimering per serie\n",
    "\n",
    "For hver tidsserie $i$, estimeres residualer og betinget volatilitet:\n",
    "\n",
    "$$\n",
    "\\varepsilon_{i,t} \\sim \\text{EGARCH}(1,1)\n",
    "$$\n",
    "\n",
    "**Kode:**\n",
    "```python\n",
    "res = arch_model(...).fit()\n",
    "res.resid # → ε_{i,t}\n",
    "res.conditional_volatility # → √{h_{i,t}}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Standardiserte residualer\n",
    "\n",
    "Standardisering gir vektor $z_t$, som er input til DCC-modellen:\n",
    "\n",
    "$$\n",
    "z_{i,t} = \\frac{\\varepsilon_{i,t}}{\\sqrt{h_{i,t}}}\n",
    "$$\n",
    "\n",
    "**Kode:**\n",
    "```python\n",
    "standardized_resid[col] = res.resid / res.conditional_volatility\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Estimering av DCC-parametere\n",
    "\n",
    "Parametrene $\\alpha$ og $\\beta$ estimeres ved å minimere DCC log-likelihood loss:\n",
    "\n",
    "$$\n",
    "\\min_{\\alpha, \\beta} \\sum_t \\left( \\log \\det R_t + z_t^\\top R_t^{-1} z_t \\right)\n",
    "$$\n",
    "\n",
    "**Kode:**\n",
    "```python\n",
    "opt_result = minimize(dcc_loss, ...)\n",
    "alpha, beta = opt_result.x\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Dynamisk kovarians\n",
    "\n",
    "Den dynamiske kovariansmatrisen $Q_t$ beskriver samvariasjonen mellom de standardiserte residualene over tid. Den beregnes rekursivt som:\n",
    "\n",
    "$$\n",
    "Q_t = (1 - \\alpha - \\beta)\\bar{Q} + \\alpha z_{t-1} z_{t-1}^\\top + \\beta Q_{t-1}\n",
    "$$\n",
    "\n",
    "hvor: \n",
    "\n",
    "$\\alpha, \\beta$ er estimert via optimering\n",
    "\n",
    "$\\bar{Q}$ er gjennomsnittlig kovariansmatrise for residualene:\n",
    "\n",
    "$$\n",
    "\\bar{Q} = \\frac{1}{T} \\sum_{t=1}^{T} z_t z_t^\\top\n",
    "$$\n",
    "\n",
    "\n",
    "**Kode:**\n",
    "```python\n",
    "Q_bar = np.cov(standardized_resid.T)\n",
    "Q_list = [...]      # alle Q_t\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Dynamisk korrelasjonsmatrise\n",
    "For å få en gyldig korrelasjonsmatrise, normaliserer vi $Q_t$ til $R_t$ slik:\n",
    "$$R_t = D_t^{-1} Q_t D_t^{-1}$$\n",
    "$$D_t = \\text{diag}\\left( \\sqrt{Q_{11,t}}, \\sqrt{Q_{22,t}}, \\dots, \\sqrt{Q_{nn,t}}  \\right)$$\n",
    "**Kode:**\n",
    "```python\n",
    "R_list = [...]      # alle R_t\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Validering og diagnostikk\n",
    "\n",
    "Loss over tid og samlet DCC-loss benyttes til evaluering:\n",
    "\n",
    "- **Total loss**:\n",
    "\n",
    "$$\n",
    "\\sum_t \\left( \\log \\det R_t + z_t^\\top R_t^{-1} z_t \\right)\n",
    "$$\n",
    "\n",
    "- **Loss per tidssteg** gir innsikt i modellens svakheter i tid.\n",
    "\n",
    "**Kode:**\n",
    "```python\n",
    "loss_values = [...]\n",
    "total_loss = sum(loss_values)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Variabeloversikt\n",
    "\n",
    "| Teoretisk symbol           | Kodevariabel                       |\n",
    "|---------------------------|------------------------------------|\n",
    "| $$s_t$$                | `transformed_prices`               |\n",
    "| $$\\Delta s_t$$        | `transformed_diff`                 |\n",
    "| $$\\varepsilon_{i,t}$$   | `res.resid`                        |\n",
    "| $$\\sqrt{h_{i,t}}$$      | `res.conditional_volatility`       |\n",
    "| $$z_{i,t}$$             | `standardized_resid`               |\n",
    "| $$Q_t $$, $$ \\bar{Q}$$  | `Q_list`, `Q_bar`                  |\n",
    "| $$R_t$$                 | `R_list`, `R_array`                |\n",
    "| $$\\alpha, \\beta$$       | `alpha`, `beta` (fra `opt_result`) |\n",
    "| DCC log-likelihood loss   | `loss_values`, `total_loss`        |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be955bce-2225-4fe1-a83d-b7938f8777d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Beregn daglige endringer i priser (robust mot null og negative verdier) ---\n",
    "daily_prices_diff = daily_prices.diff().dropna()\n",
    "\n",
    "# --- Funksjon som tester EGARCH-varianter ---\n",
    "def test_egarch_variants(\n",
    "    series: pd.Series,\n",
    "    distributions: list = [\"normal\", \"t\", \"skewt\"]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Estimerer EGARCH-modeller for en gitt serie.\n",
    "    \"\"\"\n",
    "    p_q_combos = [(1, 1)]  # Eventuelt utvid til flere kombinasjoner\n",
    "    results = []\n",
    "\n",
    "    for p, q in p_q_combos:\n",
    "        for dist in distributions:\n",
    "            try:\n",
    "                model = arch_model(series, vol=\"EGARCH\", p=p, q=q, dist=dist)\n",
    "                res = model.fit(disp=\"off\")\n",
    "                results.append({\n",
    "                    \"p\": p,\n",
    "                    \"q\": q,\n",
    "                    \"dist\": dist,\n",
    "                    \"loglikelihood\": res.loglikelihood,\n",
    "                    \"aic\": res.aic,\n",
    "                    \"bic\": res.bic\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Feil med EGARCH({p},{q}) - {dist}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# --- Estimer modeller for hver serie (bruker kun t-fordeling) ---\n",
    "results_ger = test_egarch_variants(daily_prices_diff[\"GER\"])\n",
    "results_ger[\"serie\"] = \"GER\"\n",
    "\n",
    "results_no2 = test_egarch_variants(daily_prices_diff[\"NO2\"])\n",
    "results_no2[\"serie\"] = \"NO2\"\n",
    "\n",
    "# --- Kombiner og sorter etter laveste absolutt AIC ---\n",
    "df_all = pd.concat([results_ger, results_no2], ignore_index=True)\n",
    "df_all.rename(columns={\"dist\": \"distribution\"}, inplace=True)\n",
    "df_all[\"abs_aic\"] = df_all[\"aic\"].abs()\n",
    "df_all_sorted = df_all.sort_values(by=\"abs_aic\").reset_index(drop=True)\n",
    "\n",
    "# --- Lag kolonne med modellnavn (p,q distribution) ---\n",
    "df_all_sorted[\"modell\"] = df_all_sorted.apply(\n",
    "    lambda row: f\"({row['p']},{row['q']}) {row['distribution']}\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# --- Del opp i separate tabeller for GER og NO2 ---\n",
    "df_ger = df_all_sorted[df_all_sorted[\"serie\"] == \"GER\"].reset_index(drop=True).round(2)\n",
    "df_no2 = df_all_sorted[df_all_sorted[\"serie\"] == \"NO2\"].reset_index(drop=True).round(2)\n",
    "\n",
    "# --- Vis tabeller ---\n",
    "display(df_ger.style.set_caption(f\"EGARCH-modeller for {NAME_MAP['GER']} (kun t-fordeling, sortert etter laveste |AIC|)\"))\n",
    "display(df_no2.style.set_caption(f\"EGARCH-modeller for {NAME_MAP['NO2']} (kun t-fordeling, sortert etter laveste |AIC|)\"))\n",
    "\n",
    "# --- Legg til kolonne med visningsnavn for figurer ---\n",
    "df_all_sorted[\"serie_navn\"] = df_all_sorted[\"serie\"].map(NAME_MAP)\n",
    "\n",
    "# --- Plot AIC ---\n",
    "fig_aic = px.bar(\n",
    "    df_all_sorted,\n",
    "    x=\"modell\",\n",
    "    y=\"aic\",\n",
    "    color=\"serie_navn\",\n",
    "    barmode=\"group\",\n",
    "    title=\"AIC for EGARCH-modeller med t-fordeling\",\n",
    "    labels={\"modell\": \"Modell (p,q)\", \"aic\": \"AIC\"},\n",
    "    hover_data=[\"p\", \"q\", \"distribution\", \"loglikelihood\"]\n",
    ")\n",
    "fig_aic.update_layout(title_font_size=18, legend_title_text=\"Serie\", xaxis_tickangle=-45)\n",
    "fig_aic.show()\n",
    "\n",
    "# --- Plot BIC ---\n",
    "fig_bic = px.bar(\n",
    "    df_all_sorted,\n",
    "    x=\"modell\",\n",
    "    y=\"bic\",\n",
    "    color=\"serie_navn\",\n",
    "    barmode=\"group\",\n",
    "    title=\"BIC for EGARCH-modeller med t-fordeling\",\n",
    "    labels={\"modell\": \"Modell (p,q)\", \"bic\": \"BIC\"},\n",
    "    hover_data=[\"p\", \"q\", \"distribution\", \"loglikelihood\"]\n",
    ")\n",
    "fig_bic.update_layout(title_font_size=18, legend_title_text=\"Serie\", xaxis_tickangle=-45)\n",
    "fig_bic.show()\n",
    "\n",
    "# --- Plot Log-likelihood ---\n",
    "fig_ll = px.bar(\n",
    "    df_all_sorted,\n",
    "    x=\"modell\",\n",
    "    y=\"loglikelihood\",\n",
    "    color=\"serie_navn\",\n",
    "    barmode=\"group\",\n",
    "    title=\"Log-likelihood for EGARCH-modeller med t-fordeling\",\n",
    "    labels={\"modell\": \"Modell (p,q)\", \"loglikelihood\": \"Log-likelihood\"},\n",
    "    hover_data=[\"p\", \"q\", \"distribution\", \"aic\"]\n",
    ")\n",
    "fig_ll.update_layout(title_font_size=18, legend_title_text=\"Serie\", xaxis_tickangle=-45)\n",
    "fig_ll.show()\n",
    "\n",
    "# --- Lagre til Excel ---\n",
    "excel_path = EXCEL_DIR / \"data.xlsx\"\n",
    "sheet_name = \"EGARCH-varianter\"\n",
    "\n",
    "try:\n",
    "    # Prøv å legge til hvis filen finnes\n",
    "    with ExcelWriter(excel_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "        df_all_sorted.round(2).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "except FileNotFoundError:\n",
    "    # Hvis filen ikke finnes, lag en ny\n",
    "    with ExcelWriter(excel_path, engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "        df_all_sorted.round(2).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"Lagret EGARCH-resultater til '{sheet_name}' i '{excel_path.name}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c355bbe1-85da-4996-abbf-4df59df4a75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Forbered data ---\n",
    "daily_prices_diff = daily_prices.diff().dropna()\n",
    "\n",
    "# --- Forbered datastrukturer ---\n",
    "standardized_resid = pd.DataFrame(index=daily_prices_diff.index)\n",
    "egarch_volatility = pd.DataFrame(index=daily_prices_diff.index)\n",
    "garch_models = {}\n",
    "adf_results = []\n",
    "\n",
    "# --- EGARCH-modellering + ADF- og ARCH-tester ---\n",
    "for col in daily_prices_diff.columns:\n",
    "    print(f\"\\n{'='*80}\\nModellering av serie: {col}\\n{'='*80}\")\n",
    "\n",
    "    orig_series = daily_prices[col].dropna()\n",
    "    diff_series = daily_prices_diff[col].dropna()\n",
    "\n",
    "    # ADF-tester\n",
    "    adf_stat_orig, adf_pval_orig, *_ = adfuller(orig_series)\n",
    "    adf_stat_diff, adf_pval_diff, *_ = adfuller(diff_series)\n",
    "\n",
    "    print(f\"\\nADF-test FØR differensiering:\")\n",
    "    print(f\"Statistikk = {adf_stat_orig:.4f}, p-verdi = {adf_pval_orig:.4f}\")\n",
    "    print(\"→ Stasjonær\" if adf_pval_orig < 0.05 else \"→ Ikke-stasjonær\")\n",
    "\n",
    "    print(f\"\\nADF-test ETTER differensiering:\")\n",
    "    print(f\"Statistikk = {adf_stat_diff:.4f}, p-verdi = {adf_pval_diff:.4f}\")\n",
    "    print(\"→ Stasjonær\" if adf_pval_diff < 0.05 else \"→ Ikke-stasjonær\")\n",
    "\n",
    "    adf_results.append({\n",
    "        \"Serie\": col,\n",
    "        \"ADF-statistikk (før)\": adf_stat_orig,\n",
    "        \"p-verdi (før)\": adf_pval_orig,\n",
    "        \"Stasjonær (før)\": \"Ja\" if adf_pval_orig < 0.05 else \"Nei\",\n",
    "        \"ADF-statistikk (etter)\": adf_stat_diff,\n",
    "        \"p-verdi (etter)\": adf_pval_diff,\n",
    "        \"Stasjonær (etter)\": \"Ja\" if adf_pval_diff < 0.05 else \"Nei\"\n",
    "    })\n",
    "\n",
    "    # ARCH-test før modellering\n",
    "    arch_stat_pre, arch_pval_pre, *_ = het_arch(diff_series)\n",
    "    print(f\"\\nARCH-test før modellering:\")\n",
    "    print(f\"LM-statistikk = {arch_stat_pre:.4f}, p-verdi = {arch_pval_pre:.4f}\")\n",
    "\n",
    "    # Estimer EGARCH(1,1)\n",
    "    model = arch_model(diff_series, vol=\"EGARCH\", p=1, o=1, q=1, dist=\"t\")\n",
    "    result = model.fit(disp=\"off\")\n",
    "    garch_models[col] = result\n",
    "\n",
    "    resid = result.resid\n",
    "    cond_vol = result.conditional_volatility\n",
    "    standardized = resid / cond_vol\n",
    "\n",
    "    standardized_resid[col] = standardized\n",
    "    egarch_volatility[col] = cond_vol\n",
    "\n",
    "    # ARCH-test etter modellering\n",
    "    arch_stat_post, arch_pval_post, *_ = het_arch(standardized.dropna())\n",
    "    print(f\"\\nARCH-test etter modellering:\")\n",
    "    print(f\"LM-statistikk = {arch_stat_post:.4f}, p-verdi = {arch_pval_post:.4f}\")\n",
    "\n",
    "    # Diagnostikk\n",
    "    print(\"\\nModelloppsummering:\")\n",
    "    print(result.summary())\n",
    "    print(\"\\nLjung-Box (lag 10):\")\n",
    "    print(acorr_ljungbox(standardized.dropna(), lags=10, return_df=True))\n",
    "    print(\"\\nKvadrerte residualer:\")\n",
    "    print(acorr_ljungbox(standardized.dropna()**2, lags=10, return_df=True))\n",
    "\n",
    "# --- DCC-tapsfunksjon ---\n",
    "def dcc_loss(params, residuals):\n",
    "    alpha, beta = params\n",
    "    if alpha < 0 or beta < 0 or (alpha + beta >= 1):\n",
    "        return np.inf\n",
    "    T = residuals.shape[0]\n",
    "    Q_bar = np.cov(residuals.T)\n",
    "    Q = Q_bar.copy()\n",
    "    loss = 0.0\n",
    "    for t in range(T):\n",
    "        z_t = residuals.iloc[t].values.reshape(-1, 1)\n",
    "        Q = (1 - alpha - beta) * Q_bar + alpha * (z_t @ z_t.T) + beta * Q\n",
    "        D_inv = np.diag(1 / np.sqrt(np.diag(Q)))\n",
    "        R_t = D_inv @ Q @ D_inv\n",
    "        sign, logdet = np.linalg.slogdet(R_t)\n",
    "        if sign <= 0:\n",
    "            return np.inf\n",
    "        e_t = residuals.iloc[t].values\n",
    "        loss += logdet + e_t.T @ np.linalg.inv(R_t) @ e_t\n",
    "    return loss\n",
    "\n",
    "# --- Estimer DCC ---\n",
    "opt_result = minimize(\n",
    "    dcc_loss,\n",
    "    [0.01, 0.98],\n",
    "    args=(standardized_resid.dropna(),),\n",
    "    method=\"SLSQP\",\n",
    "    constraints=[\n",
    "        {\"type\": \"ineq\", \"fun\": lambda x: x[0]},\n",
    "        {\"type\": \"ineq\", \"fun\": lambda x: x[1]},\n",
    "        {\"type\": \"ineq\", \"fun\": lambda x: 1.0 - x[0] - x[1]}\n",
    "    ],\n",
    "    options={\"disp\": True}\n",
    ")\n",
    "alpha, beta = opt_result.x\n",
    "print(f\"\\nOptimal DCC-parametere: alpha = {alpha:.4f}, beta = {beta:.4f}\")\n",
    "\n",
    "# --- Beregn dynamiske kovarianser og korrelasjoner ---\n",
    "T = len(standardized_resid.dropna())\n",
    "Q_bar = np.cov(standardized_resid.dropna().T)\n",
    "Q = Q_bar.copy()\n",
    "R_list, Q_list = [], []\n",
    "\n",
    "for t in range(T):\n",
    "    z_t = standardized_resid.dropna().iloc[t].values.reshape(-1, 1)\n",
    "    Q = (1 - alpha - beta) * Q_bar + alpha * (z_t @ z_t.T) + beta * Q\n",
    "    D_inv = np.diag(1 / np.sqrt(np.diag(Q)))\n",
    "    R_t = D_inv @ Q @ D_inv\n",
    "    Q_list.append(Q.copy())\n",
    "    R_list.append(R_t)\n",
    "\n",
    "# --- Lag DataFrames for DCC-resultater ---\n",
    "dates = standardized_resid.dropna().index\n",
    "series_names = standardized_resid.columns.tolist()\n",
    "\n",
    "dcc_covariances = pd.DataFrame({\n",
    "    f\"{series_names[0]}-{series_names[1]}\": [Q[0, 1] for Q in Q_list]\n",
    "}, index=dates)\n",
    "\n",
    "correlation_data = {}\n",
    "for i in range(len(series_names)):\n",
    "    for j in range(i + 1, len(series_names)):\n",
    "        pair = f\"{series_names[i]}-{series_names[j]}\"\n",
    "        correlation_data[pair] = [R[i, j] for R in R_list]\n",
    "\n",
    "dcc_correlations = pd.DataFrame(correlation_data, index=dates)\n",
    "\n",
    "# --- Beregn log-likelihood tap ---\n",
    "loss_values = []\n",
    "for t, R_t in enumerate(R_list):\n",
    "    sign, logdet = np.linalg.slogdet(R_t)\n",
    "    if sign <= 0:\n",
    "        continue\n",
    "    e_t = standardized_resid.dropna().iloc[t].values\n",
    "    quad_form = e_t.T @ np.linalg.inv(R_t) @ e_t\n",
    "    loss_values.append(logdet + quad_form)\n",
    "total_loss = sum(loss_values)\n",
    "print(f\"\\nTotal DCC log-likelihood loss: {total_loss:.4f}\")\n",
    "\n",
    "# --- Eksportér resultater ---\n",
    "print(\"\\nStarter eksport...\")\n",
    "adf_df = pd.DataFrame(adf_results).set_index(\"Serie\")\n",
    "save_garch_summaries_txt(garch_models)\n",
    "save_to_excel(\n",
    "    raw_prices=daily_prices,\n",
    "    differenced_prices=daily_prices_diff,\n",
    "    volatility=egarch_volatility,\n",
    "    standardized_resid=standardized_resid,\n",
    "    dcc_corrs=dcc_correlations,\n",
    "    dcc_covs=dcc_covariances,\n",
    "    dcc_loss=total_loss,\n",
    "    dcc_alpha=alpha,\n",
    "    dcc_beta=beta,\n",
    "    adf_results=adf_df\n",
    ")\n",
    "export_garch_results_to_excel(garch_models, \"data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0b8571-9dfd-4e7b-9286-82dcd59d9ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Deskriptiv analyse av daglige strømpriser ---\n",
    "descriptive_analysis(daily_prices)\n",
    "\n",
    "# --- Deskriptiv analyse av EGARCH-volatilitet ---\n",
    "descriptive_analysis(egarch_volatility)\n",
    "\n",
    "# --- Deskriptiv analyse av standardiserte residualer ---\n",
    "descriptive_analysis(standardized_resid)\n",
    "\n",
    "# --- Deskriptiv analyse av DCC-korrelasjoner ---\n",
    "descriptive_analysis(dcc_correlations)\n",
    "\n",
    "# --- Deskriptiv analyse av DCC-kovarianser ---\n",
    "descriptive_analysis(dcc_covariances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57068b64-ed9a-4566-9f4b-556a276965bc",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e655bcb0-c7ba-4c82-916c-b89e1dd2e80e",
   "metadata": {},
   "source": [
    "## Daglige strømpriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba654c-4028-46e2-b7fb-f7c96c1931e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plott tidsserie for daglige strømpriser ---\n",
    "plot_timeseries(\n",
    "    data=daily_prices,\n",
    "    title=\"Daglige strømpriser\",\n",
    "    y_title=\"Pris (EUR/MWh)\",\n",
    "    filename=\"daily_prices\",\n",
    "    show_break=True\n",
    ")\n",
    "\n",
    "# --- Plott histogram for daglige strømpriser ---\n",
    "plot_histogram(\n",
    "    data=daily_prices,\n",
    "    title=\"Daglige strømpriser\",\n",
    "    x_title=\"Pris (EUR/MWh)\",\n",
    "    filename=\"daily_prices\"\n",
    ")\n",
    "\n",
    "# --- Plott scatter-plot for daglige strømpriser ---\n",
    "plot_scatter(\n",
    "    data=daily_prices,\n",
    "    title=\"Daglige strømpriser\",\n",
    "    y_title=\"Pris (EUR/MWh)\",\n",
    "    filename=\"daily_prices\",\n",
    "    show_break=True\n",
    ")\n",
    "\n",
    "# --- Plott 7-dagers glidende gjennomsnitt for daglige strømpriser ---\n",
    "plot_rolling_average(\n",
    "    data=daily_prices,\n",
    "    window=7,\n",
    "    title=\"Strømpriser (7-dagers glidende gjennomsnitt)\",\n",
    "    y_title=\"Pris (EUR/MWh)\",\n",
    "    filename=\"daily_prices_rolling\",\n",
    "    show=True,\n",
    "    show_break=True\n",
    ")\n",
    "\n",
    "# --- Sammenlign strømpriser i Tyskland og Norge med histogram ---\n",
    "plot_histogram_comparison(\n",
    "    series1=daily_prices[\"GER\"],\n",
    "    series2=daily_prices[\"NO2\"],\n",
    "    label1=\"Tyskland\",\n",
    "    label2=\"Norge\",\n",
    "    title=\"Sammenligning av strømpriser i Tyskland og Norge\",\n",
    "    xlabel=\"Pris (EUR/MWh)\",\n",
    "    filename=\"daily_prices_comparison\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b748ca4-2a84-4dd5-bffc-b0630cf9de63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## EGARCH-volatilitet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a600bb5f-e53a-43df-aa9b-da9cc7ad782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plott EGARCH-volatilitet ---\n",
    "egarch_volatility = pd.DataFrame({\n",
    "    col: garch_models[col].conditional_volatility\n",
    "    for col in daily_prices_diff.columns\n",
    "})\n",
    "\n",
    "plot_timeseries(\n",
    "    data=egarch_volatility,\n",
    "    title=\"EGARCH-volatilitet\",\n",
    "    y_title=\"Volatilitet\",\n",
    "    filename=\"egarch_volatility\",\n",
    "    show_break=True\n",
    ")\n",
    "\n",
    "# --- Plott histogram-sammenligning av volatilitet før og etter invasjonen ---\n",
    "for col in [\"GER\", \"NO2\"]:\n",
    "    plot_histogram_comparison(\n",
    "        series1=egarch_volatility.loc[egarch_volatility.index < BREAK_DATE, col],\n",
    "        series2=egarch_volatility.loc[egarch_volatility.index >= BREAK_DATE, col],\n",
    "        label1=\"Før 24. feb 2022\",\n",
    "        label2=\"Etter 24. feb 2022\",\n",
    "        title=f\"EGARCH-volatilitet for {NAME_MAP[col]} før og etter invasjonen\",\n",
    "        xlabel=\"Volatilitet\",\n",
    "        filename=f\"egarch_volatility_{col.lower()}_histogram_comparison\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd8f677-39ec-40a8-a26a-e6ab5eb7163e",
   "metadata": {},
   "source": [
    "## EGARCH-residualer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8815134b-db1e-44c9-92c8-ae42df8b59e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plott differensierte strømpriser ---\n",
    "plot_timeseries(\n",
    "    data=daily_prices_diff,\n",
    "    title=\"Differensierte strømpriser\",\n",
    "    y_title=\"Endring i pris (EUR/MWh)\",\n",
    "    filename=\"daily_prices_diff\",\n",
    "    show_break=True\n",
    ")\n",
    "\n",
    "# --- Plott residualer fra GARCH-modellene ---\n",
    "residuals_df = pd.DataFrame({\n",
    "    col: garch_models[col].resid\n",
    "    for col in daily_prices_diff.columns\n",
    "})\n",
    "\n",
    "plot_timeseries(\n",
    "    data=residuals_df,\n",
    "    title=\"Residualer\",\n",
    "    y_title=\"Residualer\",\n",
    "    filename=\"residuals\",\n",
    "    show_break=True\n",
    ")\n",
    "\n",
    "# --- Plott standardiserte residualer ---\n",
    "plot_timeseries(\n",
    "    data=standardized_resid,\n",
    "    title=\"Standardiserte residualer\",\n",
    "    y_title=\"Standardiserte residualer\",\n",
    "    filename=\"standardized_resid\",\n",
    "    show_break=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bcdd63-7f7f-40cd-9a3e-d6f2b26e087e",
   "metadata": {},
   "source": [
    "## DCC korrelasjon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eaf04a-0a2a-4fb3-9178-a64902c5de58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plott DCC tidsvarierende korrelasjon ---\n",
    "plot_timeseries(\n",
    "    data=dcc_correlations,\n",
    "    title=\"DCC tidsvarierende korrelasjon\",\n",
    "    y_title=\"Korrelasjon\",\n",
    "    filename=\"dcc_correlations\",\n",
    "    show_break=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74f4311-6c1c-4344-ad15-d42afe8f1494",
   "metadata": {},
   "source": [
    "## DCC kovarians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca61a0f-5bc2-4a44-9967-cfd1bafe96b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plott DCC tidsvarierende kovarians ---\n",
    "plot_timeseries(\n",
    "    data=dcc_covariances,\n",
    "    title=\"DCC tidsvarierende kovarians\",\n",
    "    y_title=\"Kovarians\",\n",
    "    filename=\"dcc_covariance\",\n",
    "    show_break=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd593464-d584-40b6-b185-4ed60020d78c",
   "metadata": {},
   "source": [
    "## Sammenligning av daglige priser før og etter invasjonen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b4db8b-715c-4e55-ae6d-59b12207cd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plott histogram-sammenligning av strømpriser før og etter invasjonen ---\n",
    "for pair in daily_prices.columns:\n",
    "    name = NAME_MAP.get(pair, pair)  # Bruk visningsnavn hvis tilgjengelig\n",
    "\n",
    "    plot_histogram_comparison(\n",
    "        series1=daily_prices.loc[daily_prices.index < BREAK_DATE, pair],\n",
    "        series2=daily_prices.loc[daily_prices.index >= BREAK_DATE, pair],\n",
    "        label1=\"Før 24. feb 2022\",\n",
    "        label2=\"Etter 24. feb 2022\",\n",
    "        title=f\"Daglige strømpriser i {name} før og etter invasjonen\",\n",
    "        xlabel=\"Pris (EUR/MWh)\",\n",
    "        filename=f\"daily_prices_{pair.replace(' ', '_').replace('-', '_')}_histogram_kde\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb464cfb-db78-4ce0-a3ff-b01b3c9a2973",
   "metadata": {},
   "source": [
    "## Sammenligning av DCC-korrelasjon før og etter invasjonen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab273604-0934-47f8-82a7-cb9fb4e9d80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plott histogram-sammenligning av DCC-korrelasjoner før og etter invasjonen ---\n",
    "for pair in dcc_correlations.columns:\n",
    "    plot_histogram_comparison(\n",
    "        series1=dcc_correlations.loc[dcc_correlations.index < BREAK_DATE, pair],\n",
    "        series2=dcc_correlations.loc[dcc_correlations.index >= BREAK_DATE, pair],\n",
    "        label1=\"Før 24. feb 2022\",\n",
    "        label2=\"Etter 24. feb 2022\",\n",
    "        title=f\"Tidsvarierende korrelasjon før og etter invasjonen\",\n",
    "        xlabel=\"DCC-korrelasjon\",\n",
    "        filename=f\"dcc_correlation_{pair.replace(' ', '_').replace('-', '_')}_histogram_kde\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aa8973-1545-47e1-87f9-1c48b0154d25",
   "metadata": {},
   "source": [
    "## Sammenligning av DCC-kovarians før og etter invasjonen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954ce804-41b7-425f-9ea2-a7c89a12b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plott histogram-sammenligning av DCC-kovarianser før og etter invasjonen ---\n",
    "for pair in dcc_covariances.columns:\n",
    "    plot_histogram_comparison(\n",
    "        series1=dcc_covariances.loc[dcc_covariances.index < BREAK_DATE, pair],\n",
    "        series2=dcc_covariances.loc[dcc_covariances.index >= BREAK_DATE, pair],\n",
    "        label1=\"Før 24. feb 2022\",\n",
    "        label2=\"Etter 24. feb 2022\",\n",
    "        title=f\"Tidsvarierende kovarians før og etter invasjonen\",\n",
    "        xlabel=\"DCC-kovarians\",\n",
    "        filename=f\"dcc_covariance_{pair.replace(' ', '_').replace('-', '_')}_histogram_kde\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca38156-ff7f-4a41-86f0-2e5725c53410",
   "metadata": {},
   "source": [
    "## QQ-plot for residualer og standardiserte residualer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3b4441-4a4e-4845-9a31-c6ded54c81fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plott QQ-plot for residualer og standardiserte residualer ---\n",
    "for col in daily_prices_diff.columns:\n",
    "    # Sett farger basert på kolonnenavn\n",
    "    if \"GER\" in col:\n",
    "        color = COLOR_1  # Tyskland\n",
    "    elif \"NO2\" in col:\n",
    "        color = COLOR_2  # Norge (NO2)\n",
    "    else:\n",
    "        color = COLOR_3  # Fallback-farge\n",
    "\n",
    "    # Definer datasett (vanlige og standardiserte residualer)\n",
    "    datasets = [\n",
    "        (garch_models[col].resid.dropna(), \"residualer\", color),\n",
    "        (standardized_resid[col].dropna(), \"standardiserte residualer\", color)\n",
    "    ]\n",
    "\n",
    "    for data, label, color in datasets:\n",
    "        safe_label = label.replace(\" \", \"_\").lower()\n",
    "        filename = f\"qq_{col.lower()}_{safe_label}\"\n",
    "\n",
    "        plot_qq(\n",
    "            data=data,\n",
    "            label=label,\n",
    "            color=color,\n",
    "            title=f\"{NAME_MAP.get(col, col)} – QQ-plot for\",\n",
    "            filename=filename\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3674f400-6a11-484b-b0f1-feae859bb059",
   "metadata": {},
   "source": [
    "## ACF og PACF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdfd729-b946-41ca-97d6-454536896346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plott ACF og PACF for råpriser (nivådata) ---\n",
    "plot_acf_pacf(\n",
    "    series=daily_prices[\"GER\"],\n",
    "    title_prefix=\"Tyskland – priser\",\n",
    "    lags=20\n",
    ")\n",
    "\n",
    "plot_acf_pacf(\n",
    "    series=daily_prices[\"NO2\"],\n",
    "    title_prefix=\"Norge – priser\",\n",
    "    lags=20\n",
    ")\n",
    "\n",
    "# --- Plott ACF og PACF for differensierte priser ---\n",
    "plot_acf_pacf(\n",
    "    series=daily_prices_diff[\"GER\"],\n",
    "    title_prefix=\"Tyskland – differensierte priser\",\n",
    "    lags=20\n",
    ")\n",
    "\n",
    "plot_acf_pacf(\n",
    "    series=daily_prices_diff[\"NO2\"],\n",
    "    title_prefix=\"Norge – differensierte priser\",\n",
    "    lags=20\n",
    ")\n",
    "\n",
    "# --- Plott ACF og PACF for EGARCH-residualer ---\n",
    "plot_acf_pacf(\n",
    "    series=standardized_resid[\"GER\"],\n",
    "    title_prefix=\"Tyskland – EGARCH-residualer\",\n",
    "    lags=20\n",
    ")\n",
    "\n",
    "plot_acf_pacf(\n",
    "    series=standardized_resid[\"NO2\"],\n",
    "    title_prefix=\"Norge – EGARCH-residualer\",\n",
    "    lags=20\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "name": "DCC_analyse_garch"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
